Metadata-Version: 2.4
Name: llm_discord_bot
Version: 0.0.0
Summary: Discord chatbot that utilizes a local LLM for processing with a learning RAG pipeline
Author-email: Joshua von Damm <jvondamm@gmail.com>
Project-URL: Repository, https://github.com/Jvondamm/llm_discord_bot
Classifier: Programming Language :: Python :: 3
Classifier: operating System :: OS Independent
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: discord>=2.3.2
Requires-Dist: dotenv>=0.9.9
Requires-Dist: torch>=2.6.0
Requires-Dist: transformers>=4.51.3
Requires-Dist: accelerate>=1.6.0
Requires-Dist: datasets>=3.5.1
Requires-Dist: sentence-transformers>=2.2.2
Requires-Dist: faiss-cpu>=1.7.4
Requires-Dist: langchain-community>=0.3.23
Requires-Dist: langchain-huggingface>=0.1.2
Requires-Dist: bitsandbytes>=0.45.5
Requires-Dist: table2ascii==1.1.3
Requires-Dist: faiss-cpu>=1.11.0
Provides-Extra: dev
Requires-Dist: pre-commit>=4.2.0; extra == "dev"
Requires-Dist: ruff>=0.11.6; extra == "dev"
Requires-Dist: uv>=0.6.16; extra == "dev"

If not running with uv, install dependencies with 

pip install .

To develop, install the extra dependencies with

pip install .[dev]

If you get 'Torch not compiled with CUDA enabled'
then navigate to https://pytorch.org/get-started/locally/ and select the correct options for your system (run nvcc --version) to figure out your CUDA version,
then run the pip install command that is generated.
After the installation, do

import torch
torch.cuda.is_available()
 to verify the installation
