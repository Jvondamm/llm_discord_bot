[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llm_discord_bot"
dynamic = ["version"]
authors = [ { name="Joshua von Damm", email="jvondamm@gmail.com" } ]
description = "Discord chatbot that utilizes a local LLM for processing with a learning RAG pipeline"
readme = "README.md"
requires-python = ">=3.9.0"
classifiers = [
    "Programming Language :: Python :: 3",
    "Operating System :: OS Independent",
]
dependencies = [
    "accelerate>=1.8.1",
    "bitsandbytes>=0.46.0 ; sys_platform != 'darwin'",
    "datasets>=3.6.0",
    "discord>=2.3.2",
    "faiss-cpu>=1.11.0",
    "huggingface-hub>=0.33.1",
    "langchain-community>=0.3.26",
    "langchain-huggingface>=0.3.0",
    "pip-system-certs>=4.0 ; sys_platform == 'darwin'",
    "python-dotenv>=1.1.1",
    "sentence-transformers>=4.1.0",
    "table2ascii>=1.1.3",
    "torch>=2.7.1",
    "torchaudio>=2.7.1",
    "torchvision>=0.22.1",
    "transformers>=4.53.0",
]

[project.optional-dependencies]
dev = [
    "pre-commit",
    "ruff",
    "uv",
    "fabric",
    "hatch"
]

[project.scripts]
ldbot = "llm_discord_bot.__main__:main"

[project.urls]
Repository = "https://github.com/Jvondamm/llm_discord_bot"


[tool.uv.sources]
torch = [
    { index = "torch-gpu", marker = "platform_system == 'linux'"},
    { index = "torch-gpu", marker = "platform_system == 'windows'"}
]

[[tool.uv.index]]
name = "torch-gpu"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[tool.hatch.version]
path = "src/llm_discord_bot/__init__.py"

[tool.ruff]
line-length = 150
exclude = [
    "bot.env",
    "config.json"
]


