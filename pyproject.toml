[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llm_discord_bot"
dynamic = ["version"]
authors = [ { name="Joshua von Damm", email="jvondamm@gmail.com" } ]
description = "Discord chatbot that utilizes a local LLM for processing with a learning RAG pipeline"
readme = "README.md"
requires-python = ">=3.9.0"
classifiers = [
    "Programming Language :: Python :: 3",
    "Operating System :: OS Independent",
]
dependencies = [
    "discord",
    "python-dotenv",
    "transformers",
    "accelerate",
    "datasets",
    "sentence-transformers",
    "faiss-cpu",
    "langchain-community",
    "langchain-huggingface",
    "bitsandbytes; sys_platform != 'darwin'",
    "table2ascii",
    "faiss-cpu",
    "torch",
    "torchvision",
    "torchaudio",
    "pip-system-certs; sys_platform == 'darwin'"  # Sometimes had SSL cert issues on mac OS only
]

[project.optional-dependencies]
dev = [
    "pre-commit",
    "ruff",
    "uv",
    "fabric",
    "hatch"
]

[project.scripts]
ldbot = "llm_discord_bot.__main__:main"

[project.urls]
Repository = "https://github.com/Jvondamm/llm_discord_bot"


[tool.uv.sources]
torch = [
    { index = "torch-gpu", marker = "platform_system == 'linux'"},
    { index = "torch-gpu", marker = "platform_system == 'windows'"}
]

[[tool.uv.index]]
name = "torch-gpu"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[tool.hatch.version]
path = "src/llm_discord_bot/__init__.py"

[tool.ruff]
line-length = 150
exclude = [
    "bot.env",
    "config.json"
]


