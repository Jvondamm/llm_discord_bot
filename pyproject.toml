[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llm_discord_bot"
dynamic = ["version"]
authors = [ { name="Joshua von Damm", email="jvondamm@gmail.com" } ]
description = "Discord chatbot that utilizes a local LLM for processing with a learning RAG pipeline"
readme = "README.md"
requires-python = ">=3.9.0"
classifiers = [
    "Programming Language :: Python :: 3",
    "Operating System :: OS Independent",
]
dependencies = [
    "discord",
    "python-dotenv",
    "transformers",
    "accelerate",
    "datasets",
    "sentence-transformers",
    "faiss-cpu",
    "langchain-community",
    "langchain-huggingface",
    "bitsandbytes",
    "table2ascii",
    "faiss-cpu",
    "torch",
    "torchvision",
    "torchaudio"
]

[project.optional-dependencies]
dev = [
    "pre-commit",
    "ruff",
    "uv",
    "fabric",
    "hatch"
]

[project.scripts]
ldbot = "llm_discord_bot.__main__:main"

[project.urls]
Repository = "https://github.com/Jvondamm/llm_discord_bot"


[tool.uv.sources]
torch = [
    { index = "torch-gpu", marker = "platform_system == 'Linux'"},
    { index = "torch-gpu", marker = "platform_system == 'Windows'"}
]

[[tool.uv.index]]
name = "torch-gpu"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[tool.hatch.version]
path = "src/llm_discord_bot/__init__.py"

[tool.ruff]
line-length = 150
exclude = [
    "bot.env",
    "config.json"
]

log_format = "%(asctime)s.%(msecs)%03d %(levelname)-8s %(name)-15s [%(filename)s:%(lineno)d] %(message)s"
log_date_format = "%Y-%m-%d %H:%M:%S"
